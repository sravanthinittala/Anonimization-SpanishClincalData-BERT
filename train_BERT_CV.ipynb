{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-sgUbzBXPZK"
      },
      "outputs": [],
      "source": [
        "!pip install -U accelerate\n",
        "!pip install -U transformers seqeval[gpu]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJi_NJNhSb-a",
        "outputId": "00c4a310-ac42-4be4-9e40-ea9f2b1445aa"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate seqeval[gpu]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEnlUbgm8z3B"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLbYrB5-ql56"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "def read_data(file_path):\n",
        "    file_path = Path(file_path)\n",
        "\n",
        "    raw_text = file_path.read_text().strip()\n",
        "    #print(raw_text[:100])\n",
        "    raw_docs = re.split(r'\\n', raw_text)\n",
        "    print(raw_docs[:100])\n",
        "    token_docs = []\n",
        "    tag_docs = []\n",
        "    for doc in raw_docs:\n",
        "        tokens = []\n",
        "        tags = []\n",
        "        for line in doc.split('\\n'):\n",
        "            if len(line) < 3:\n",
        "              continue\n",
        "            token, tag, sentence= line.split('\\t')\n",
        "            tokens.append(token)\n",
        "            tags.append(tag)\n",
        "        token_docs.append(tokens)\n",
        "        tag_docs.append(tags)\n",
        "\n",
        "    return token_docs, tag_docs\n",
        "\n",
        "texts, tags = read_data('output.tsv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm1krxJtKxpx",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyqQJGyZJATd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_text,val_text, train_tags,  val_tags = train_test_split(texts,tags, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZq3oNgzTsH1"
      },
      "outputs": [],
      "source": [
        "unique_tags = set(tag for doc in tags for tag in doc)\n",
        "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
        "id2tag = {id: tag for tag, id in tag2id.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G--cM-RyJ_Q2"
      },
      "outputs": [],
      "source": [
        "label_list = list(unique_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1m5dttFgJ_MA"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizerFast\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-multilingual-uncased')\n",
        "\n",
        "#train_texts = train_data['Token'].tolist()\n",
        "#val_texts = val_data['Token'].tolist()\n",
        "\n",
        "\n",
        "train_encodings = tokenizer(train_text, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "val_encodings = tokenizer(val_text, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwSJR7M5ORDW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def encode_tags(tags, encodings):\n",
        "  print(tags[:10])\n",
        "  labels = [[tag2id[tag] for tag in doc] for doc in tags]\n",
        "  encoded_labels = []\n",
        "  for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
        "        # create an empty array of -100\n",
        "    doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n",
        "    arr_offset = np.array(doc_offset)\n",
        "\n",
        "    # set labels whose first offset position is 0 and the second is not 0\n",
        "    doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
        "    encoded_labels.append(doc_enc_labels.tolist())\n",
        "\n",
        "  return encoded_labels\n",
        "\n",
        "#train_tags = train_data['Tag'].tolist()\n",
        "#val_tags = val_data['Tag'].tolist()\n",
        "\n",
        "train_labels = encode_tags(train_tags, train_encodings)\n",
        "val_labels = encode_tags(val_tags, val_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmPQe55uffA_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class MEDOCCANDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_encodings.pop(\"offset_mapping\") # we don't want to pass this to the model\n",
        "val_encodings.pop(\"offset_mapping\")\n",
        "train_dataset = MEDOCCANDataset(train_encodings, train_labels)\n",
        "val_dataset = MEDOCCANDataset(val_encodings, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZmryA-PgvcP"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForTokenClassification\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-multilingual-cased', num_labels=len(unique_tags))\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TL3Igcamv54b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    # Flatten the predictions and labels for sklearn's classification_report\n",
        "    labels_flat = [label for sublist in labels for label in sublist]\n",
        "    preds_flat = [pred for sublist in preds for pred in sublist]\n",
        "\n",
        "    # Generate classification report\n",
        "    classification_rep = classification_report(labels_flat, preds_flat, output_dict=True)\n",
        "\n",
        "    # Calculate overall metrics\n",
        "    overall_metrics = {\n",
        "        \"accuracy\": classification_rep['accuracy'],\n",
        "        \"precision\": classification_rep['macro avg']['precision'],\n",
        "        \"recall\": classification_rep['macro avg']['recall'],\n",
        "        \"f1_score\": classification_rep['macro avg']['f1-score']\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"overall\": overall_metrics\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HTSutCzGtmQ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3b26f0af25b54c47a63749204a50f22d",
            "78363f2c418042eaa55496b80ba80286",
            "3c683be4ed9844ffb4e3705204d54b0f",
            "c067126974df4fa4bcb110f7fe859d94",
            "a305bea1cdf642d7941faed977f615e7",
            "e3f2cef5251440fb80b54e0f4385509c",
            "e30ac082ad904a62a9f650af6ce79181",
            "066c4d4ae47745c4887d2ec8d72633ce",
            "ea401c1d86324bac90d51b4fc0b4ec85",
            "3d581be105844fe98f0d37878ce3e7c1",
            "8a7fee8683034b01bca4145c6a311eee"
          ]
        },
        "id": "QXaCzcLqGuQm",
        "outputId": "f1cac377-f7e2-424a-daef-34f66ce3e5f7"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "seqeval = evaluate.load(\"seqeval\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "id": "FXBooA0JuvVK",
        "outputId": "97ff1aba-b36b-441c-c8fe-fd4a2253aa4d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from transformers import Trainer, TrainingArguments, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# Defining test dataset\n",
        "test_texts, test_tags = read_data('test.tsv')\n",
        "test_encodings = tokenizer(test_texts, is_split_into_words=True,\n",
        "                          return_offsets_mapping=True, padding=True,\n",
        "                           truncation=True)\n",
        "test_labels = encode_tags(test_tags, test_encodings)\n",
        "test_dataset = MEDOCCANDataset(test_encodings, test_labels)  # Replace with your actual test dataset\n",
        "\n",
        "# Initialize an empty list to store predictions\n",
        "all_test_predictions = []\n",
        "\n",
        "k = 3  # Number of folds\n",
        "kf = KFold(n_splits=k, shuffle=True)\n",
        "\n",
        "# Initialize your model, tokenizer, datasets, and other components\n",
        "\n",
        "for fold, (train_index, eval_index) in enumerate(kf.split(train_encodings)):\n",
        "    print(f\"Training fold {fold + 1}/{k}\")\n",
        "\n",
        "    # Split data into train and eval for this fold\n",
        "    train_inputs_fold = [train_encodings[i] for i in train_index]\n",
        "    train_labels_fold = [train_labels[i] for i in train_index]\n",
        "    eval_inputs_fold = [val_encodings[i] for i in eval_index]\n",
        "    eval_labels_fold = [val_labels[i] for i in eval_index]\n",
        "\n",
        "    # Instantiate your Trainer and TrainingArguments for this fold\n",
        "    training_args_fold = TrainingArguments(\n",
        "        output_dir=f'./results_fold_{fold}',  # Directory for results\n",
        "        num_train_epochs=3,                  # Total number of training epochs\n",
        "        per_device_train_batch_size=12,       # Batch size per GPU\n",
        "        logging_dir=f'./logs_fold_{fold}',    # Directory for storing logs\n",
        "        save_strategy = \"epoch\",                       # Save model checkpoint every 500 steps\n",
        "        evaluation_strategy=\"epoch\",          # Evaluate at the end of each epoch\n",
        "        logging_steps=100,                    # Log metrics every 100 steps\n",
        "        learning_rate=3e-5,                   # Learning rate\n",
        "        gradient_accumulation_steps=1,        # Number of updates steps before backward pass\n",
        "        weight_decay=0.0,                     # Weight decay (if applicable)\n",
        "        adam_beta1=0.9,                       # AdamW beta1\n",
        "        adam_beta2=0.999,                     # AdamW beta2\n",
        "        adam_epsilon=1e-8,                    # AdamW epsilon\n",
        "        max_grad_norm=1.0,                    # Gradient clipping threshold\n",
        "        warmup_steps=500,                     # Number of warmup steps for the scheduler\n",
        "        load_best_model_at_end=True,          # Load the best model when training ends\n",
        "        metric_for_best_model='eval_loss',    # Metric to use to determine the best model\n",
        "        greater_is_better=False               # Indicate if higher metric values are better\n",
        "    )\n",
        "\n",
        "    # Instantiate AdamW optimizer and scheduler for this fold\n",
        "    optimizer_fold = AdamW(model.parameters(), lr=training_args_fold.learning_rate,\n",
        "                           betas=(training_args_fold.adam_beta1, training_args_fold.adam_beta2),\n",
        "                           eps=training_args_fold.adam_epsilon)\n",
        "    num_training_steps_fold = len(train_inputs_fold) // (training_args_fold.per_device_train_batch_size *\n",
        "                                                        training_args_fold.gradient_accumulation_steps) * training_args_fold.num_train_epochs\n",
        "    scheduler_fold = get_linear_schedule_with_warmup(optimizer_fold, num_warmup_steps=training_args_fold.warmup_steps,\n",
        "                                                    num_training_steps=num_training_steps_fold)\n",
        "\n",
        "    # Initialize Trainer for this fold\n",
        "    trainer_fold = Trainer(\n",
        "        model=model,\n",
        "        args=training_args_fold,\n",
        "        optimizers=(optimizer_fold,scheduler_fold),\n",
        "        train_dataset= MEDOCCANDataset(train_encodings, train_labels),\n",
        "        eval_dataset= MEDOCCANDataset(val_encodings, val_labels),\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train the model for this fold\n",
        "    trainer_fold.train()\n",
        "\n",
        "    # Evaluate the model for this fold\n",
        "    evaluation_result = trainer_fold.evaluate()\n",
        "    print(f\"Evaluation result for fold {fold + 1}/{k}:\")\n",
        "    print(evaluation_result)\n",
        "    test_predictions = trainer_fold.predict(test_dataset)\n",
        "    all_test_predictions.append(test_predictions)\n",
        "    model.save_pretrained(f\"./model/best_model_fold_{fold + 1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQG5ClHpzcc4"
      },
      "outputs": [],
      "source": [
        "# Calculate aggregated predictions on the test set\n",
        "final_test_predictions = np.argmax(np.mean([pred.predictions for pred in all_test_predictions], axis=0), axis=-1)\n",
        "\n",
        "# True labels for the test set\n",
        "true_labels_test = [label for sublist in test_labels for label in sublist]\n",
        "\n",
        "# Calculate metrics for the test set\n",
        "test_classification_report = classification_report(true_labels_test, final_test_predictions)\n",
        "test_confusion_matrix = confusion_matrix(true_labels_test, final_test_predictions)\n",
        "\n",
        "# Print or use the classification report and confusion matrix\n",
        "print(\"Test Classification Report:\")\n",
        "print(test_classification_report)\n",
        "\n",
        "print(\"Test Confusion Matrix:\")\n",
        "print(test_confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJV8fSsbz6Kx"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments, AdamW, get_linear_schedule_with_warmup, AutoConfig, AutoModelForTokenClassification\n",
        "\n",
        "\n",
        "# After saving, you can upload your model to the Hugging Face Model Hub using the following command in the terminal\n",
        "!transformers-cli login  # Log in to your Hugging Face account\n",
        "!transformers-cli repo create NER-BERT-MEDOCCAN-KFold  # Create a new repository for your model\n",
        "!transformers-cli push './model/'  # Push your saved model to the Hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-RSX2-AhLim"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset             # evaluation dataset\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wbskCTQrwy0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "066c4d4ae47745c4887d2ec8d72633ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b26f0af25b54c47a63749204a50f22d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78363f2c418042eaa55496b80ba80286",
              "IPY_MODEL_3c683be4ed9844ffb4e3705204d54b0f",
              "IPY_MODEL_c067126974df4fa4bcb110f7fe859d94"
            ],
            "layout": "IPY_MODEL_a305bea1cdf642d7941faed977f615e7"
          }
        },
        "3c683be4ed9844ffb4e3705204d54b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_066c4d4ae47745c4887d2ec8d72633ce",
            "max": 6338,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea401c1d86324bac90d51b4fc0b4ec85",
            "value": 6338
          }
        },
        "3d581be105844fe98f0d37878ce3e7c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78363f2c418042eaa55496b80ba80286": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3f2cef5251440fb80b54e0f4385509c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e30ac082ad904a62a9f650af6ce79181",
            "value": "Downloading builder script: 100%"
          }
        },
        "8a7fee8683034b01bca4145c6a311eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a305bea1cdf642d7941faed977f615e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c067126974df4fa4bcb110f7fe859d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d581be105844fe98f0d37878ce3e7c1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8a7fee8683034b01bca4145c6a311eee",
            "value": " 6.34k/6.34k [00:00&lt;00:00, 113kB/s]"
          }
        },
        "e30ac082ad904a62a9f650af6ce79181": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3f2cef5251440fb80b54e0f4385509c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea401c1d86324bac90d51b4fc0b4ec85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
